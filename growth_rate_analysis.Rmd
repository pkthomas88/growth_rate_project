---
title: "Growth rate analysis"
author: "Patrick Thomas"
date: "Nov 7 2021"
output: 
  html_document:
    number_sections: true
    toc: true
    toc_float:
      collapsed: true
---


# Setup, data import and checking

> load packages and set theme

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(psych)
library(growthrates)
library(knitr)
library(growthrates)
library(googledrive)
library(cowplot)
library(broom)
library(growthcurver)


theme_set(theme_bw()+
            theme(axis.text=element_text(size=16),
  axis.title.x = element_text(size = 16),
  axis.title.y = element_text(size = 16),
  strip.text = element_text(size=16)))

```

> run the following to install growthTools and its required packages, if necessary

```{r}
# install.packages("remotes")
# remotes::install_github("ctkremer/mleTools")
# remotes::install_github("ctkremer/growthTools")
library(growthTools)

```

## Code for combining files, **skip this if using compiled dataset**

> create list of files to combine

```{r}

#create list of growth data files
growth_files <- list.files("C:/Users/pktho/OneDrive/Growth rates paper/growth_rate_project", # change this based on location of files
                        pattern = "growthdata.csv",  # Limit to just files ending in growthdata.csv
                        recursive = TRUE,  # Search within subfolders
                        full.names = TRUE) # Return full paths

growth_files

# create list of metadata files
metadata_files <- list.files("C:/Users/pktho/OneDrive/Growth rates paper/growth_rate_project", # change this based on location of files
                        pattern = "metadata.csv",  # Limit to just files ending in growthdata.csv
                        recursive = TRUE,  # Search within subfolders
                        full.names = TRUE) # Return full paths

metadata_files

```


> combine data files based on above list

```{r}
df <- lapply(growth_files, function(i){
  x=read_csv(i, na = "NA", col_types = cols(colonial = col_character(),
                                            time_acclimation = col_character(),
                                            RFU_excitation_emission = col_character()))
  x$filename = i
  x
})

#df[[1]] # to look at a certain data file for example

df=do.call("bind_rows", df) # binds all data frames read in above, but requires same column names or it will create duplicat columns!

#combine researcher ID with unique ID to make sure it's unique across all datasets
df <- df %>% mutate(unique_ID = paste(researcher_ID, unique_ID, sep = '_'))

```

> combine metadata files based on above metadata file list

```{r}

metadata <- lapply(metadata_files, function(i){
  x=read_csv(i, na = "NA", col_types = cols(colonial = col_character(),
                                            time_acclimation = col_character(),
                                            RFU_excitation_emission = col_character()))
  x$filename = i
  x
})

metadata=do.call("bind_rows", metadata)
metadata <- metadata %>% mutate(unique_ID = paste(researcher_ID, unique_ID, sep = '_'))

```


> stuff I have to do for now since metadata is in different places for different people

```{r}

df <- df %>% select(researcher_ID:cell_density)
df_Vanessa <- df %>% filter(researcher_ID=="Vanessa")
df_Vanessa <- left_join(df_Vanessa, metadata)
df <- df %>% filter(researcher_ID!="Vanessa")
df <- bind_rows(df, df_Vanessa)

```

> calculate sampling intervals, total number samples [probably add more things here later e.g., hour to day conversions, other stuff like that if necessary]

```{r}

df <- df %>% 
  #calculate number of observations and time between all observations
  group_by(unique_ID) %>% 
  mutate(time_points = length(time_days),
            interval = time_days - dplyr::lag(time_days, n =1)) 

df <- left_join(df, metadata)

#write_csv(df, "combined_data.csv") write combined dataset to csv

```

# **Start here if using full combined dataset**

```{r}

df <- read_csv("combined_data.csv")

df <- df %>% mutate(log_RFU_platereader = log(RFU_platereader+1))

```

>check out the combined data in several ways to make sure it all makes sense and was imported correctly

```{r}

dim(df)
names(df)
str(df)
summary(df)
summary_data <- describe(df)
kable(summary_data)
length(unique(df$unique_ID)) #how many total growth rate estimates will we have?
df %>% group_by(researcher_ID) %>% 
  summarize(count = length(unique(unique_ID)))#look at how many growth rates we'll have per person

#I don't think 0s should exist and don't work with growthrates package so maybe these are a mistake?
df %>% filter(RFU_platereader==0)

```


> some plots for fun and to look at outliers and the spread of the data

```{r}

df %>%
  ggplot(aes(time_days, RFU_platereader, color = researcher_ID))+
  geom_point(alpha=.2)

df %>%
  ggplot(aes(OD, RFU_platereader, color = researcher_ID))+
  geom_point(alpha=.2)

df %>% filter(OD<1.5) %>% 
  ggplot(aes(OD, RFU_platereader, color = researcher_ID))+
  geom_point(alpha=.2)

df %>% filter(time_days <0.05) %>% 
  ggplot(aes(RFU_platereader))+
  geom_histogram()+
  facet_wrap(~researcher_ID, scales = 'free')+
  ggtitle("a look at initial densities in RFU for y0 info: \na bit of a big range now so maybe can't use the same parameters for all..?")


df %>% 
  ggplot(aes(time_points))+
  geom_histogram()

df %>% 
  ggplot(aes(interval))+
  geom_histogram()

```


# Test runs with reduced datasets

> making a small test dataset for trying different approaches, taking the first 20 experimental units where growth rate was measured [here I was too tired/stupid to figure out how to loop it by person, hence the copy/pasted code :/]

```{r}

A <- df %>% filter(researcher_ID=="AH")
IDs <- unique(A$unique_ID)
A_test <- A %>% filter(unique_ID %in% IDs[1:10])
unique(A_test$unique_ID)

B <- df %>% filter(researcher_ID=="IG")
IDs <- unique(B$unique_ID)
B_test <- B %>% filter(unique_ID %in% IDs[1:10])
unique(B_test$unique_ID)


# C <- df %>% filter(researcher_ID=="MG")
# IDs <- unique(C$unique_ID)
# C_test <- C %>% filter(unique_ID %in% IDs[1:10])
# unique(C_test$unique_ID)

D <- df %>% filter(researcher_ID=="Patrick")
IDs <- unique(D$unique_ID)
D_test <- D %>% filter(unique_ID %in% IDs[1:10])
unique(D_test$unique_ID)

E <- df %>% filter(researcher_ID=="Vanessa")
IDs <- unique(E$unique_ID)
E_test <- E %>% filter(unique_ID %in% IDs[1:10])
unique(E_test$unique_ID)

test <- bind_rows(A_test, B_test, D_test, E_test)
unique(test$unique_ID)
summary(test)
test %>% count(unique_ID)

#0s still a problem so removing those
test %>% filter(RFU_platereader==0)
test <- filter(test, RFU_platereader>0)

```

# !! include this chunk only if you want to turn 'test' into full dataset and run >3000 growth rate fits!

```{r}

# test <- df %>% 
#   filter(RFU_platereader>0)

```


> we can have this as a supplementary figure about the computing power needed for fitting many growth rates...

![](R_session_fail.png)

## `growthrates` spline

> here the splines function doesn't let you log-transform the y axis as with others, not sure whether to use logRFU here?

```{r cache=TRUE}

start_time <- Sys.time()

test_spline_fits <- all_splines(RFU_platereader ~ time_days | unique_ID + researcher_ID, data = test, spar=0.5)

par(mfrow = c(4, 6))
par(mar=c(1,2,1,1))
#plot(test_spline_fits, log = "y")

end_time <- Sys.time()

elapsed_time_spline <- end_time - start_time

test_spline_results <- results(test_spline_fits) %>% 
  mutate(model = "growthrates::spline",
         elapsed_time=elapsed_time_spline) %>% 
  select(researcher_ID, unique_ID, mumax, model, r2, elapsed_time)

```



## `growthrates` logistic

> try this with and without the lower and upper parameter values, as these are optional??

```{r cache=TRUE}
summary(test$RFU_platereader)
summary(test)

start_time <- Sys.time()

# setting a huge range of parameters to fit all data with varying RFU
p     <- c(y0 = 10, mumax = 0.5, K = 100)
lower <- c(y0 = 0, mumax = -5,   K = 0)
upper <- c(y0 = 100, mumax = 5,   K = 5000)

test_logistic_fits <- all_growthmodels(
                   RFU_platereader ~ grow_logistic(time_days, parms) | unique_ID +researcher_ID,
                   data = test,
                   p = p, lower = lower, upper = upper,
                   log = "y")

end_time <- Sys.time()

elapsed_time_logistic <- end_time - start_time

test_logistic_results <- results(test_logistic_fits) %>% 
  mutate(model = "growthrates::logistic",
         elapsed_time=elapsed_time_logistic) %>% 
  select(researcher_ID, unique_ID, mumax, model, r2, elapsed_time)

```

> that approach took `r round(as.numeric(elapsed_time_logistic), 2)` seconds to calculate `r length(unique(test$unique_ID))` growth rates

> plotting above curves

```{r cache=TRUE}

par(mfrow = c(4, 6))
par(mar=c(1,2,1,1))
#plot(test_logistic_fits, log = "y")

```

## `growthrates` easy linear

> this gives an error message about object m missing, no idea what's up with that

```{r cache=TRUE}

test_easylinear_fits <- all_easylinear(RFU_platereader ~ time_days|unique_ID+researcher_ID,
                                       h =3, #change h to change width of window used
                                       data = test)

easylinear_model <- all_easylinear(RFU_platereader ~ time_hours | unique_ID,
                                       data = growth_data, h = 3) # parameter h indicates how many datapoints are used to estimate the slope, it can be increased depending on the data


par(mfrow = c(4, 6))
par(mar=c(1,2,1,1))
plot(test_easylinear_fits, log = "y")

```


## `growthrates` exponential

```{r cache=TRUE}
start_time <- Sys.time()

p     <- c(y0 = 5, mumax = 0.5)
lower <- c(y0 = 0, mumax = -5)
upper <- c(y0 = 20, mumax = 5)

test_exp_fits <- all_growthmodels(
                   RFU_platereader ~ grow_exponential(time_days, parms) | unique_ID + researcher_ID,
                   data = test,
                   p = p, lower = lower, upper = upper,
                   log = "y")

end_time <- Sys.time()

elapsed_time_exp <- end_time - start_time

test_exp_results <- results(test_exp_fits) %>% 
  mutate(model = "growthrates::exp",
         elapsed_time=elapsed_time_exp) %>% 
  select(researcher_ID, unique_ID, mumax, model, r2, elapsed_time)

par(mfrow = c(4, 6))
par(mar=c(1,2,1,1))
#plot(test_exp_fits, log = "y")

```



## `growthTools`

```{r}

start_time <- Sys.time()


# estimate the best growth model for all 
growth_rates <- test %>%
  group_by(unique_ID, researcher_ID) %>%
  do(grs = get.growth.rate(x = .$time_days, y = .$log_RFU_platereader, 
                           methods = c("linear", "lag", "sat", "flr", "lagsat"),
                           model.selection = c("AICc"),
                           id = .$unique_ID, plot.best.Q = F, fpath = NA))

end_time <- Sys.time()

growth_rates$ictab

elapsed_time_growthtools <- end_time - start_time

# get important parameters of the models
summary_growth_rates <- growth_rates %>% 
  summarise(unique_ID, researcher_ID, 
            mu = grs$best.slope, # mu of the best model
            best_model = grs$best.model, # name of the best model
            best.model_r2 = grs$best.model.rsqr, # r squared of the best model
            best_se = grs$best.se, # standard error of the best model
            contents = grs$best.model.contents) # best model


#renaming some things to match headers from growthrates package
growthtools_test <- summary_growth_rates %>% 
  rename(mumax=mu) %>%
  mutate(model = paste("growthtools::", best_model),
         r2=best.model_r2,
         elapsed_time = elapsed_time_growthtools) %>% 
  select(researcher_ID, unique_ID, mumax, model, r2, elapsed_time)
  

```

## Growthcurver package

```{r}

test_wide <- test %>% 
  pivot_wider(names_from = unique_ID)

,
              values_from = c("RFU_platereader", "time_days"))

head(test_wide)



```



## sequential fit/sliding window

```{r}

# phosphate_abundances %>% 
#   ggplot(aes(x = days, y = log(RFU), color = phosphate_concentration, group = well_plate)) + geom_point() +
#   # geom_smooth(method = "lm") +
#   geom_line() +
#   facet_wrap( ~ population)



start_time <- Sys.time()

# PT: what exactly is the top_N(-x) doing here? and also the map_df? and what exactly does iteration mean?

fitting_window <- function(x) {
  growth_rates <- test %>% 
    top_n(n = -x, wt = time_days) %>% 
    group_by(unique_ID, researcher_ID, system) %>% 
    do(tidy(lm(log(RFU_platereader) ~ time_days, data = .))) %>% 
    mutate(number_of_points = x) %>% 
    ungroup()
}

fitting_window_log_linear <- function(x) {
  growth_rates <- test %>% 
    group_by(unique_ID, researcher_ID, system) %>% 
    top_n(n = -x, wt = time_days) %>% 
    do(tidy(lm(log(RFU_platereader) ~ time_days, data = .))) %>% 
    mutate(number_of_points = x) %>% 
    ungroup()
}

windows <- seq(3,7, by = 1) ## these are the minimum and maximum number 
                            #  of time points included in the window

multi_fits <- windows %>% #this does not work for any growth curves....
  map_df(fitting_window, .id = "iteration")

multi_fits <- windows %>% #this works for almost all growth curves
  map_df(fitting_window_log_linear, .id = "iteration")


multi_fits %>% 
  filter(term == "time_days") %>% 
  ggplot(aes(x = number_of_points, y = estimate, group = unique_ID, color = researcher_ID)) + geom_point() + geom_line()

exp_fits_top <- multi_fits %>%
  filter(term == "time_days") %>% 
  group_by(unique_ID) %>% 
  top_n(n = 1, wt = estimate)

exp_fits_top_SD <- multi_fits %>%
  filter(term == "time_days") %>% 
  group_by(unique_ID) %>% 
  top_n(n = 1, wt = std.error) %>% 
  rename(estimateSD = estimate)

end_time <- Sys.time()
elapsed_time_sequential <- end_time-start_time

both <- left_join(exp_fits_top, exp_fits_top_SD, by = "unique_ID")

ggplot(both, aes(estimate, estimateSD))+
  geom_point()

exp_fits_top %>% 
  filter(term =="time_days") %>% 
  ggplot(aes(estimate, fill = researcher_ID))+
    geom_density(alpha = 0.7)


sequential_fit <- exp_fits_top %>% 
  mutate(model="sequential_fit") %>% 
  mutate(r2 = "NA") %>%# can get Rsquare, just ignoring for now
  mutate(r2=as.numeric(r2)) %>% 
  rename(mumax = estimate) %>% 
  mutate(elapsed_time = elapsed_time_sequential)

#write_csv(sequential_fit, "sequential_fit.csv")

```



## manual - max increase over 2 days

```{r}

start_time <- Sys.time()

max_diffs <- test %>% 
  mutate(logRFU = log(RFU_platereader)) %>% 
  group_by(unique_ID, researcher_ID) %>% 
  mutate(deltalogRFU = logRFU - dplyr::lag(logRFU, n=2)) %>% 
  mutate(deltatime = time_days - dplyr::lag(time_days, n=2)) %>% 
  mutate(mu = deltalogRFU/deltatime)

max_rates <- max_diffs %>% 
  group_by(unique_ID, researcher_ID, system) %>% 
  summarize(mumax = max(mu, na.rm = TRUE)) %>% 
  mutate(model="max_diff_2days") %>% 
  mutate(r2 = "NA") %>%
  mutate(r2=as.numeric(r2)) %>% 
  ungroup()

end_time <- Sys.time()
maxdiff_time <- end_time - start_time

max_rates <- max_rates %>% 
  mutate(elapsed_time = maxdiff_time)

```

## Combining all data


```{r}
combined_test <- bind_rows(test_spline_results,
                           test_logistic_results,
                           test_exp_results,
                           growthtools_test,
                           max_rates,
                           sequential_fit)

summary(combined_test)

write_csv(combined_test, "combinedtest.csv")

```


## plots of combined data

```{r}

A <- combined_test %>% 
  ggplot(aes(model, r2))+
  geom_boxplot(fill = "dark green")+
  coord_flip()+
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

B <- combined_test %>% 
  ggplot(aes(model, mumax))+
  geom_boxplot(fill = "dark green")+
  coord_flip()

plot_grid(B, A, vjust = TRUE, rel_widths = c(2,1))

combined_test %>% 
  ggplot(aes(model, elapsed_time))+
  coord_flip()+
  geom_bar(stat = 'identity', fill = "dark green")+
  ylab('Elapsed time (seconds)')

```





# Growth rate calculations for full dataset

> quickly trying the 2-point growth rate approach by taking the max increase over between two adjacent time points (i.e., either 1, 2, or 4 days depending on the sampling interval)

```{r}
start_time <- Sys.time()

max_diffs <- df %>% 
  mutate(logRFU = log(RFU_platereader)) %>% 
  group_by(unique_ID, researcher_ID, system) %>% 
  mutate(deltalogRFU = logRFU - dplyr::lag(logRFU, n=1)) %>% 
  mutate(deltatime = time_days - dplyr::lag(time_days, n=1)) %>% 
  mutate(mu = deltalogRFU/deltatime)

max_rates <- max_diffs %>% 
  group_by(unique_ID, researcher_ID, system) %>% 
  summarize(mumax = max(mu, na.rm = TRUE)) %>% 
  mutate(model="max_diff_2days") %>% 
  mutate(r2 = "NA") %>%
  mutate(r2=as.numeric(r2))

end_time <- Sys.time()
maxdiff_time <- end_time - start_time

```

> that approach took `r round(as.numeric(maxdiff_time), 2)` seconds to calculate `r length(max_rates$mumax)` growth rates

>also there are a lot of NA and Inf values so need to check why that is....

```{r}
max_rates %>% ggplot(aes(mumax, fill = system))+
  geom_density(alpha = 0.7)

max_rates %>% ggplot(aes(mumax, fill = researcher_ID))+
  geom_density(alpha = 0.7)

```


```{r}

knitr::knit_exit()


```


# To do:

- add AIC data to everything possible
- add R2 to sequential fits
- 



> notes so far:

- combining data works pretty well overall!
- differences in formatting stuff like commas vs periods and different column names are minor problems but can be fixed
- running the full dataset in the `growthrates` package might kill my computer


> one way to measure time taken for e.g. growth rate calculations

```{r}
sleep_for_a_minute <- function() { Sys.sleep(5) }
start_time <- Sys.time()
sleep_for_a_minute()
end_time <- Sys.time()
end_time - start_time

```
